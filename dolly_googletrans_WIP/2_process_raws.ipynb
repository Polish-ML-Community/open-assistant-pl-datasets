{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "context_raw_path = Path('./dolly_ggltrans/context_trans_raw/context_en')\n",
    "response_raw_path = Path('./dolly_ggltrans/response_trans_raw/response_en/')\n",
    "dolly_instructions_path = Path('./dolly_ggltrans/dolly_instruction_en_translated.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "context_raw_df = pd.concat([pd.read_csv(x) for x in context_raw_path.glob('*.csv')])\n",
    "response_raw_df = pd.concat([pd.read_csv(x) for x in response_raw_path.glob('*.csv')])\n",
    "dolly_instructions_df = pd.read_json(dolly_instructions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_raw_df = (\n",
    "    context_raw_df\n",
    "    .rename(columns={'Unnamed: 0':'index'})\n",
    "    .set_index('index')\n",
    "    [['context_en_trans']]\n",
    ")\n",
    "response_raw_df = (\n",
    "    response_raw_df\n",
    "    .rename(columns={'Unnamed: 0':'index'})\n",
    "    .set_index('index')\n",
    "    [['response_en_trans']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_raw_df['context_en_trans'] = context_raw_df['context_en_trans'].apply(ast.literal_eval)\n",
    "response_raw_df['response_en_trans'] = response_raw_df['response_en_trans'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_raw_df['context_success'], context_raw_df['context_pl'] = zip(*context_raw_df['context_en_trans'])\n",
    "response_raw_df['response_success'], response_raw_df['response_pl'] = zip(*response_raw_df['response_en_trans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_raw_df = context_raw_df.drop(columns='context_en_trans')\n",
    "response_raw_df = response_raw_df.drop(columns='response_en_trans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data and clean\n",
    "dolly_interim = dolly_instructions_df.merge(\n",
    "    context_raw_df,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "dolly_trans = dolly_interim.merge(\n",
    "    response_raw_df,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "dolly_trans = dolly_trans.drop(columns='Unnamed: 0')\n",
    "trans_fields = ['instruction_en', 'context_en', 'response_en', 'instruction_pl', 'context_pl', 'response_pl']\n",
    "for field in trans_fields:\n",
    "    dolly_trans[field] = dolly_trans[field].str.strip()\n",
    "    dolly_trans[field] = dolly_trans[field].fillna('')\n",
    "    dolly_trans[field] = dolly_trans[field].str.replace(r'^(Zero|Null)$', '', regex=True)\n",
    "    dolly_trans[field] = dolly_trans[field].replace('', np.nan)\n",
    "\n",
    "## QA\n",
    "missing_instructions_en = dolly_trans['instruction_en'].isnull().sum()\n",
    "missing_contexts_en = dolly_trans['context_en'].isnull().sum()\n",
    "missing_responses_en = dolly_trans['response_en'].isnull().sum()\n",
    "\n",
    "missing_instructions_pl = dolly_trans['instruction_pl'].isnull().sum()\n",
    "missing_contexts_pl = dolly_trans['context_pl'].isnull().sum()\n",
    "missing_responses_pl = dolly_trans['response_pl'].isnull().sum()\n",
    "\n",
    "missing_change_instr = missing_instructions_pl - missing_instructions_en\n",
    "missing_change_context = missing_contexts_pl - missing_contexts_en\n",
    "missing_change_response = missing_responses_pl - missing_responses_en\n",
    "\n",
    "print(missing_change_instr, missing_change_context, missing_change_response)\n",
    "\n",
    "for field in ['instr_trans_success','context_success','response_success']:\n",
    "    print(field)\n",
    "    print(dolly_trans[field].sum())\n",
    "    print(dolly_trans[field].sum()/dolly_trans.shape[0])\n",
    "\n",
    "# Zapisz dataset\n",
    "dolly_trans.to_json('./dolly_ggltrans/dolly_ggltranslated.json')\n",
    "dolly_trans.to_csv('./dolly_ggltrans/dolly_ggltranslated.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
